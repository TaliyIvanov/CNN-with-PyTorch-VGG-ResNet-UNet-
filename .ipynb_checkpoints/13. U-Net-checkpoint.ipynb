{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e645efd-0adb-485c-be85-0e38999d121c",
   "metadata": {},
   "source": [
    "### Немного теории"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eba514-fd57-4c06-888a-ec2e98e909f5",
   "metadata": {},
   "source": [
    "**U-Net: Архитектура для Сегментации Изображений**\n",
    "\n",
    "**Основная идея:** U-Net - это архитектура сверточной нейронной сети, разработанная специально для задач **сегментации изображений**. Она отличается своей U-образной формой и способностью захватывать как контекст изображения (где находится объект), так и точное местоположение пикселей объекта.\n",
    "\n",
    "**Ключевые особенности:**\n",
    "\n",
    "*   **U-образная форма:** Архитектура состоит из двух основных частей:\n",
    "    *   **Сжимающий путь (Encoder):** Левая часть U-образной формы. Он постепенно уменьшает пространственное разрешение признаков (размер карт признаков), извлекая контекстную информацию из изображения.\n",
    "    *   **Расширяющий путь (Decoder):** Правая часть U-образной формы. Он постепенно увеличивает пространственное разрешение карт признаков, восстанавливая точное местоположение объектов.\n",
    "*   **Сверточные слои (Convolutional Layers):** Используются для извлечения признаков из изображения.\n",
    "*   **Слои макс-пулинга (Max-Pooling):** Используются в сжимающем пути для уменьшения разрешения признаков и улавливания более общего контекста.\n",
    "*   **Слои транспонированной свертки (Transposed Convolution, Up-convolution):** Используются в расширяющем пути для увеличения разрешения карт признаков.\n",
    "*   **Соединительные переходы (Skip Connections):** Ключевая особенность U-Net. Они соединяют соответствующие слои сжимающего и расширяющего путей. Это позволяет объединить контекстную информацию с информацией о точном местоположении.\n",
    "\n",
    "**Алгоритм работы U-Net:**\n",
    "\n",
    "1.  **Вход:** Изображение подается на вход сети.\n",
    "2.  **Сжимающий путь (Encoder):**\n",
    "    *   Изображение проходит через последовательность сверточных слоев и слоев макс-пулинга.\n",
    "    *   На каждом этапе пространственное разрешение признаков уменьшается, а количество каналов увеличивается (за счет количества фильтров).\n",
    "    *   На этом этапе происходит извлечение контекстных признаков изображения.\n",
    "3.  **Переход к расширяющему пути:** На самом низком уровне U-образной формы.\n",
    "4.  **Расширяющий путь (Decoder):**\n",
    "    *   Карты признаков из сжимающего пути проходят через последовательность слоев транспонированной свертки и сверточных слоев.\n",
    "    *   На каждом этапе пространственное разрешение признаков увеличивается.\n",
    "    *   На этом этапе восстанавливается точное местоположение объектов на основе контекстных признаков.\n",
    "    *   Происходит конкатенация (\"склеивание\") карт признаков с соответствующих слоев сжимающего пути с помощью соединительных переходов (skip connections).\n",
    "5.  **Соединительные переходы (Skip Connections):**\n",
    "    *   Карты признаков с соответствующих слоев сжимающего пути конкатенируются с картами признаков с расширяющего пути.\n",
    "    *   Это позволяет передать информацию о точном местоположении из сжимающего пути в расширяющий, что помогает восстановить детализированную маску сегментации.\n",
    "6.  **Выход:** На выходе получается карта сегментации (маска) того же размера, что и входное изображение, где каждый пиксель классифицируется как принадлежащий к определенному классу (например, объект или фон).\n",
    "\n",
    "**Зачем нужны skip connections?**\n",
    "\n",
    "*   Skip connections помогают решить проблему потери информации о местоположении пикселей в процессе свертки и пулинга.\n",
    "*   Они позволяют объединить высокоуровневый контекст с низкоуровневыми деталями, что очень важно для точной сегментации.\n",
    "\n",
    "**Применение U-Net:**\n",
    "\n",
    "*   Медицинская визуализация (сегментация опухолей, органов).\n",
    "*   Автономное вождение (сегментация дорожной сцены).\n",
    "*   Спутниковые снимки (сегментация объектов на местности).\n",
    "*   Обработка изображений в целом (сегментация объектов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437b467-b9f7-49e0-996a-074e1eb70a01",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033d4410-0f0b-48c5-aa3a-0649416ea24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c50af-3966-43e5-bc0a-a9991067c73c",
   "metadata": {},
   "source": [
    "### Class DoubleConv: Двойная свертка с активацией ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ef761-48f2-4b01-8eec-0a3000b85750",
   "metadata": {},
   "source": [
    "Этот класс `DoubleConv` представляет собой модуль нейронной сети, реализующий последовательность из двух сверточных слоев с активацией ReLU после каждого слоя. \n",
    "\n",
    "Он используется как базовый строительный блок в более сложных архитектурах, таких как U-Net.\n",
    "\n",
    "**Функциональность:**\n",
    "\n",
    "`DoubleConv` принимает тензор входных данных и выполняет следующие операции:\n",
    "\n",
    "1. **Первая свертка:** Применяет сверточный слой `conv1` с размером ядра 3x3 и отступом 1 к входному тензору. Это позволяет сохранить пространственные размеры на выходе.\n",
    "2. **Активация ReLU:** Применяет функцию активации ReLU к результату первой свертки, внося нелинейность в модель.\n",
    "3. **Вторая свертка:** Применяет сверточный слой `conv2` с размером ядра 3x3 и отступом 1 к результату предыдущего шага.  Количество входных и выходных каналов в этом слое равно `out_channels`.\n",
    "4. **Активация ReLU:** Применяет функцию активации ReLU к результату второй свертки.\n",
    "\n",
    "**Параметры:**\n",
    "\n",
    "* `in_channels` (int): Количество входных каналов.\n",
    "* `out_channels` (int): Количество выходных каналов.\n",
    "\n",
    "**Методы:**\n",
    "\n",
    "* `__init__(self, in_channels, out_channels)`: Конструктор класса.  Инициализирует два сверточных слоя `conv1` и `conv2` с заданными параметрами и функцию активации `ReLU`.\n",
    "* `forward(self, x)`:  Выполняет прямой проход данных через модуль. Принимает входной тензор `x` и возвращает тензор `out` после применения двух сверток и активаций ReLU.\n",
    "\n",
    "В этом примере создается экземпляр `DoubleConv` с 3 входными каналами и 64 выходными каналами.  Этот модуль может будет использован как часть более сложной нейронной сети.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a49315c-41f8-4826-9c48-9413768ab2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, (3,3), padding=1)\n",
    "        self.act = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        out = self.act(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478bdd6b-f9af-41ab-b008-391040df78cb",
   "metadata": {},
   "source": [
    "Class DownSample: Блок понижающей дискретизации с двойной сверткой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694c3a8c-435d-4d30-a752-464bc771f2ff",
   "metadata": {},
   "source": [
    "Класс `DownSample` представляет собой модуль нейронной сети, который выполняет понижающую дискретизацию (downsampling) входного тензора, комбинируя двойную свертку и операцию max pooling. Этот блок часто используется в архитектурах кодировщика, таких как U-Net, для уменьшения пространственных размеров и увеличения количества каналов.\n",
    "\n",
    "**Функциональность:**\n",
    "\n",
    "`DownSample` принимает тензор входных данных и выполняет следующие операции:\n",
    "\n",
    "1. **Двойная свертка:** Применяет модуль `DoubleConv` (описанный ранее) к входному тензору. `DoubleConv` выполняет две последовательные свертки 3x3 с отступом 1 и активацией ReLU после каждого слоя.  Это позволяет извлечь более сложные признаки из входных данных.\n",
    "2. **Max Pooling:** Применяет операцию `MaxPool2d` с размером ядра 2x2 и шагом 2 к результату двойной свертки. Это уменьшает пространственные размеры тензора в два раза по каждой оси (высота и ширина).\n",
    "\n",
    "**Параметры:**\n",
    "\n",
    "* `in_channels` (int): Количество входных каналов.\n",
    "* `out_channels` (int): Количество выходных каналов для `DoubleConv`.\n",
    "\n",
    "**Методы:**\n",
    "\n",
    "* `__init__(self, in_channels, out_channels)`: Конструктор класса. Инициализирует модуль `DoubleConv` с заданными входными и выходными каналами, а также слой `MaxPool2d` с ядром 2x2.\n",
    "* `forward(self, x)`: Выполняет прямой проход данных через модуль. Принимает входной тензор `x` и возвращает два тензора:\n",
    "    * `out_double_conv`: Результат применения `DoubleConv` к входному тензору (до понижающей дискретизации).\n",
    "    * `out_down`: Результат применения `MaxPool2d` к выходу `DoubleConv` (после понижающей дискретизации).  Этот тензор имеет уменьшенные пространственные размеры и `out_channels` каналов.\n",
    "\n",
    "**Возвращаемые значения:**\n",
    "\n",
    "* `out_double_conv`: Тензор с результатом двойной свертки.  Сохраняется для использования в skip connections в архитектурах типа U-Net.\n",
    "* `out_down`: Тензор с результатом понижающей дискретизации. Используется в качестве входных данных для следующего блока в кодировщике.\n",
    "\n",
    "В этом примере создается экземпляр `DownSample` с 3 входными каналами и 64 выходными каналами для `DoubleConv`. Этот модуль может быть использован как часть кодировщика в более сложной нейронной сети.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecad6d70-64e8-4e20-a0f1-71f65e97749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_double_conv = self.double_conv(x)\n",
    "        out_down = self.down(out_double_conv)\n",
    "\n",
    "        return out_double_conv, out_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964d7c3-c9cb-4aa0-a732-53870868ac6a",
   "metadata": {},
   "source": [
    "### Class UpSample: Блок повышающей дискретизации с двойной сверткой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f18ef1-1c92-4e7a-a137-f3c763f68811",
   "metadata": {},
   "source": [
    "Класс `UpSample` представляет собой модуль нейронной сети, выполняющий повышающую дискретизацию (upsampling) входного тензора и конкатенацию с тензором из skip connection. Этот блок часто используется в архитектурах декодера, таких как U-Net, для увеличения пространственных размеров и комбинирования информации с более ранних слоев кодировщика.\n",
    "\n",
    "**Функциональность:**\n",
    "\n",
    "`UpSample` принимает два тензора в качестве входных данных:\n",
    "\n",
    "* `x1`: Тензор с меньшими пространственными размерами, который нужно увеличить.  Это как правило, выход предыдущего слоя декодера.\n",
    "* `x2`: Тензор из skip connection с соответствующего слоя кодировщика. Он имеет те же пространственные размеры, что и результат `x1` после upsampling.\n",
    "\n",
    "`UpSample` выполняет следующие операции:\n",
    "\n",
    "1. **Транспонированная свертка:** Применяет `ConvTranspose2d` (также известную как деконволюция) к тензору `x1`.  Это увеличивает пространственные размеры `x1` в два раза  с помощью заданного шага (stride) 2 и размера ядра 2x2.  Результат имеет `out_channels` каналов.\n",
    "2. **Конкатенация:** Конкатенирует тензор `x1` после upsampling с тензором `x2` по оси каналов (dim=1).  Это объединяет информацию из skip connection с результатом upsampling.\n",
    "3. **Двойная свертка:** Применяет модуль `DoubleConv` (описанный ранее) к конкатенированному тензору.  `DoubleConv` выполняет две последовательные свертки 3x3 с отступом 1 и активацией ReLU после каждого слоя. Это помогает сгладить артефакты upsampling и извлечь более сложные признаки из объединенной информации.\n",
    "\n",
    "**Параметры:**\n",
    "\n",
    "* `in_channels` (int): Количество входных каналов для `ConvTranspose2d`. Должно соответствовать количеству каналов в `x1`.\n",
    "* `out_channels` (int): Количество выходных каналов для `ConvTranspose2d` и `DoubleConv`.\n",
    "\n",
    "**Методы:**\n",
    "\n",
    "* `__init__(self, in_channels, out_channels)`: Конструктор класса. Инициализирует слой транспонированной свертки `up` и модуль `DoubleConv` с заданными параметрами.\n",
    "* `forward(self, x1, x2)`: Выполняет прямой проход данных через модуль. Принимает два входных тензора `x1` и `x2`, выполняет upsampling, конкатенацию и двойную свертку, и возвращает результирующий тензор `out`.\n",
    "\n",
    "В этом примере создается экземпляр `UpSample`, который принимает тензор с 256 каналами, увеличивает его размер, конкатенирует с тензором из skip connection и применяет двойную свертку с 128 выходными каналами.  Этот модуль может быть использован как часть декодера в U-Net или подобной архитектуре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4733e4-1efc-4978-bd33-412a0b530ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, (2,2), stride=2)\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        out = self.double_conv(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87975835-5e86-44ed-8564-8e0a5853f05e",
   "metadata": {},
   "source": [
    "### Class U-Net: Сегментационная нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a5f298-1391-4fda-9b51-a3a2d640ba7b",
   "metadata": {},
   "source": [
    "Этот код реализует архитектуру U-Net, популярную сверточную нейронную сеть, предназначенную для задач сегментации изображений. U-Net имеет симметричную U-образную структуру, состоящую из кодировщика (downsampling path) и декодера (upsampling path). Кодировщик извлекает признаки из изображения, а декодер восстанавливает пространственное разрешение, комбинируя информацию из кодировщика с помощью skip connections.\n",
    "\n",
    "**Архитектура:**\n",
    "\n",
    "1. **Кодировщик (Downsampling Path):**\n",
    "   - Состоит из четырех блоков `DownSample`. Каждый блок выполняет двойную свертку (`DoubleConv`) с последующим max pooling, уменьшая пространственное разрешение в два раза и увеличивая количество каналов.\n",
    "   - Последовательность блоков `DownSample`: `down1` (64 канала), `down2` (128 каналов), `down3` (256 каналов), `down4` (512 каналов).\n",
    "\n",
    "2. **Bottleneck:**\n",
    "   - Модуль `DoubleConv` с 1024 каналами, расположенный в самой нижней части U-образной структуры.  Обрабатывает выход последнего блока кодировщика.\n",
    "\n",
    "3. **Декодер (Upsampling Path):**\n",
    "   - Состоит из четырех блоков `UpSample`. Каждый блок выполняет транспонированную свертку для увеличения пространственного разрешения в два раза, конкатенирует результат с соответствующим выходом из кодировщика (skip connection) и применяет `DoubleConv` для обработки объединенной информации.\n",
    "   - Последовательность блоков `UpSample`: `up1` (512 каналов), `up2` (256 каналов), `up3` (128 каналов), `up4` (64 канала).  Обратите внимание, что количество каналов симметрично кодировщику.\n",
    "\n",
    "4. **Выходной слой:**\n",
    "   - Сверточный слой `out` с ядром 1x1, преобразующий 64 канала в `num_classes` выходных каналов.  Каждый канал соответствует определенному классу для сегментации.\n",
    "\n",
    "\n",
    "**Параметры:**\n",
    "\n",
    "* `in_channels` (int): Количество входных каналов (по умолчанию 3 для RGB изображений).\n",
    "* `num_classes` (int): Количество классов для сегментации (по умолчанию 1 для бинарной сегментации).\n",
    "\n",
    "\n",
    "**Методы:**\n",
    "\n",
    "* `__init__(self, in_channels, num_classes)`: Конструктор, инициализирующий все слои U-Net.\n",
    "* `forward(self, x)`: Выполняет прямой проход данных через сеть.\n",
    "\n",
    "\n",
    "**Алгоритм работы U-Net:**\n",
    "\n",
    "1. **Вход:** Изображение подается на вход сети.\n",
    "2. **Кодировщик:** Изображение проходит через последовательность блоков `DownSample`, уменьшаясь в размере и увеличивая количество каналов. На каждом этапе сохраняется выход `DoubleConv` (до max pooling) для skip connections (`sk1`, `sk2`, `sk3`, `sk4`).\n",
    "3. **Bottleneck:**  Самое сжатое представление изображения обрабатывается в bottleneck слое.\n",
    "4. **Декодер:**  Выход bottleneck проходит через последовательность блоков `UpSample`. На каждом этапе:\n",
    "    - Пространственное разрешение увеличивается с помощью транспонированной свертки.\n",
    "    - Результат конкатенируется с соответствующим выходом из кодировщика (skip connection).\n",
    "    - Объединенная информация обрабатывается `DoubleConv`.\n",
    "5. **Выход:**  Финальный слой `out` производит карту сегментации с `num_classes` каналами.  Каждый пиксель на карте соответствует определенному классу.\n",
    "\n",
    "\n",
    "**В заключение:** U-Net эффективно использует skip connections для комбинирования информации из разных уровней детализации, что позволяет получать точные результаты сегментации.  Архитектура широко применяется в медицинской обработке изображений, спутниковой съемке и других областях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1b1bda-05f9-4e3d-b75b-1e509b95d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.down1 = DownSample(in_channels, 64)\n",
    "        self.down2 = DownSample(64, 128)\n",
    "        self.down3 = DownSample(128, 256)\n",
    "        self.down4 = DownSample(256, 512)\n",
    "\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "\n",
    "        self.up1 = UpSample(1024, 512)\n",
    "        self.up2 = UpSample(512, 256)\n",
    "        self.up3 = UpSample(256, 128)\n",
    "        self.up4 = UpSample(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, num_classes, (1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        sk1, x = self.down1(x)\n",
    "        sk2, x = self.down2(x)\n",
    "        sk3, x = self.down3(x)\n",
    "        sk4, x = self.down4(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        x = self.up1(x, sk4)\n",
    "        x = self.up2(x, sk3)\n",
    "        x = self.up3(x, sk2)\n",
    "        x = self.up4(x, sk1)\n",
    "\n",
    "        out = self.out(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a52c603-8adf-4512-8e8f-84daef351e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (down1): DownSample(\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (down): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down2): DownSample(\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (down): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down3): DownSample(\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (down): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down4): DownSample(\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (down): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottleneck): DoubleConv(\n",
       "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (up1): UpSample(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up2): UpSample(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up3): UpSample(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up4): UpSample(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (out): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7902d687-9f87-46dc-8a3c-edf618f717db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.rand([1, 3, 512, 512])\n",
    "\n",
    "pred = model(inp)\n",
    "print(pred.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
