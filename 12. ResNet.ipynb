{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0203ed04-3af8-47a4-a866-c913bda80bdd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b31977f-1c24-415f-8334-e407731fac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# импорты для готовых реализаций ResNet в torchvision\n",
    "import torchvision\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd34c5-a548-43ec-b5aa-c8b453fd45bc",
   "metadata": {},
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddefe90-bb63-451f-a00d-a01959f95da4",
   "metadata": {},
   "source": [
    "Функции `conv3x3` и `conv1x1` являются вспомогательными функциями для создания сверточных слоев с ядрами размером 3x3 и 1x1 соответственно. Они упрощают создание блоков ResNet, делая код более читаемым и менее громоздким.\n",
    "\n",
    "Разберем каждую функцию:\n",
    "\n",
    "**`conv3x3(in_channels, out_channels, stride=1)`:**\n",
    "\n",
    "* **`in_channels`:** Количество входных каналов.\n",
    "* **`out_channels`:** Количество выходных каналов (количество фильтров в сверточном слое).\n",
    "* **`stride=1`:** Шаг свертки. По умолчанию равен 1 (окно свертки сдвигается на один пиксель).\n",
    "* **`kernel_size=(3, 3)`:** Размер ядра свертки - 3x3.\n",
    "* **`padding=1`:**  Добавление отступа размером 1 пиксель по краям входного тензора.  Это обеспечивает сохранение пространственных размеров выходного тензора при `stride=1`.  `padding=1`  для ядра 3x3 - это \"same\" padding.\n",
    "* **`bias=False`:**  Отключает использование bias (свободного члена) в сверточном слое. В ResNet bias часто отключают, так как Batch Normalization, применяемый после свертки, уже выполняет сдвиг активаций.\n",
    "\n",
    "\n",
    "**`conv1x1(in_channels, out_channels, stride=1)`:**\n",
    "\n",
    "* **`in_channels`:** Количество входных каналов.\n",
    "* **`out_channels`:** Количество выходных каналов.\n",
    "* **`stride=1`:** Шаг свертки.\n",
    "* **`kernel_size=(1, 1)`:** Размер ядра свертки - 1x1.  Свертка 1x1  действует как линейное преобразование в каждом пикселе, позволяя изменять количество каналов (уменьшать или увеличивать) без изменения пространственных размеров.\n",
    "* **`bias=False`:** Отключает использование bias.\n",
    "\n",
    "\n",
    "**Зачем нужны эти функции?**\n",
    "\n",
    "* **Читаемость кода:** Использование этих функций делает код более компактным и легким для понимания, скрывая детали создания сверточных слоев.\n",
    "* **Повторное использование:**  Они позволяют избежать дублирования кода при создании множества сверточных слоев с одинаковыми параметрами.\n",
    "* **Модификация:**  Если нужно изменить параметры сверточных слоев (например, добавить bias или изменить тип padding), достаточно изменить эти функции, а не все места, где они используются.\n",
    "\n",
    "\n",
    "**В контексте ResNet:**\n",
    "\n",
    "* `conv3x3` используется в `BasicBlock` для извлечения признаков.\n",
    "* `conv1x1` используется в `Bottleneck` для уменьшения и увеличения количества каналов (\"сжатие\" и \"расширение\" в бутылочном горлышке), а также в `downsample` слоях для согласования размерностей.  Свертки 1x1 позволяют эффективно управлять количеством каналов, уменьшая вычислительную сложность модели.\n",
    "\n",
    "\n",
    "В заключение, `conv3x3` и `conv1x1` - это удобные вспомогательные функции, которые делают код ResNet более чистым, модульным и легким для поддержки.  Они инкапсулируют логику создания сверточных слоев с определенными параметрами, что способствует лучшей организации кода.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a888f597-7149-4d1a-a18d-fda14941e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=(3,3),\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=(1,1),\n",
    "        stride=stride,\n",
    "        bias=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb42e2-b5de-4790-b4ed-a1cb1298dfa2",
   "metadata": {},
   "source": [
    "### Basic block\n",
    "\n",
    "Рализация класса для базового блока"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631a09c-e01d-46de-90ea-302e09c8bed3",
   "metadata": {},
   "source": [
    "Этот код определяет класс `BasicBlock`, который является базовым строительным блоком для архитектуры ResNet (Residual Network). Он реализует *residual connection* - ключевую концепцию ResNet, которая позволяет обучать очень глубокие нейронные сети, эффективно передавая градиенты и предотвращая проблему затухающих градиентов.\n",
    "\n",
    "Разберем подробнее:\n",
    "\n",
    "**1. `expansion = 1`:** Этот атрибут указывает, что количество выходных каналов блока равно количеству каналов, заданных в `out_channels`. В `BasicBlock` нет расширения каналов, в отличие от `Bottleneck` блока, где `expansion` обычно равно 4.\n",
    "\n",
    "**2. `__init__(self, in_channels, out_channels, stride=1, downsample=None)`:**  Конструктор класса.\n",
    "\n",
    "* **`in_channels`:** Количество входных каналов.\n",
    "* **`out_channels`:** Количество выходных каналов (и каналов в промежуточных слоях, так как `expansion = 1`).\n",
    "* **`stride`:** Шаг свертки. `stride=1` означает, что окно свертки сдвигается на один пиксель. `stride=2` уменьшит пространственные размеры карты признаков вдвое. Применяется в `self.conv1`.\n",
    "* **`downsample`:** Опциональный аргумент. Если `stride > 1` или `in_channels != out_channels`, то `downsample` используется для преобразования входного тензора `x`, чтобы его размерность соответствовала размерности `out`. Это обычно реализуется с помощью свертки 1x1 и Batch Normalization.  Это необходимо для того, чтобы сложение в residual connection было корректным по размерностям.\n",
    "\n",
    "\n",
    "**3. `forward(self, x)`:** Метод, определяющий прямой проход данных через блок.\n",
    "\n",
    "* **`identity = x`:** Сохраняет входной тензор `x` для использования в residual connection.  Это \"shortcut\" ветка.\n",
    "* **`out = self.conv1(x)` ... `out = self.bn2(out)`:** Два сверточных слоя 3x3 (`conv3x3`) с Batch Normalization (`bn1`, `bn2`) и ReLU активацией (`relu`) между ними. Это основная ветка обработки, где происходит извлечение признаков. Обратите внимание, что `stride` применяется только к первому сверточному слою `conv1`.\n",
    "* **`if self.downsample is not None: identity = self.downsample(x)`:** Если `downsample` задан (т.е. если нужно изменить размерность входного тензора), он применяется к `x`, чтобы сделать его совместимым по размерности с `out` перед сложением.\n",
    "* **`out += identity`:**  **Ключевой момент - residual connection.** Выход основной ветки (`out`) складывается с преобразованным или исходным входным тензором (`identity`). Это позволяет градиентам более эффективно распространяться во время обучения.\n",
    "* **`out = self.relu(out)`:** ReLU активация применяется к результату суммирования.\n",
    "\n",
    "\n",
    "**В итоге:** `BasicBlock` выполняет два сверточных слоя 3x3 и добавляет результат к исходному (или преобразованному) входу. Это позволяет сети изучать *остаточные* преобразования, которые могут быть более легкими для обучения, чем изучение полной трансформации. `downsample` используется для согласования размерностей при необходимости. `BasicBlock` является одним из основных строительных блоков ResNet и вносит существенный вклад в его способность к обучению очень глубоких сетей.  Он проще, чем `Bottleneck` блок, и используется в более \"легких\" вариантах ResNet (например, ResNet18, ResNet34).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a271a65-9f41-46a9-9793-fee6dfb4d6c7",
   "metadata": {},
   "source": [
    "**expansion**\n",
    "\n",
    "В данном фрагменте кода `expansion = 1` является атрибутом класса `BasicBlock`.  Он используется для управления количеством выходных каналов в блоке ResNet.  В частности, он определяет, во сколько раз количество выходных каналов (`out_channels`) больше, чем количество каналов в промежуточных слоях блока.\n",
    "\n",
    "В `BasicBlock`, `expansion = 1` означает, что количество выходных каналов равно количеству каналов, переданных в `out_channels` в конструкторе.  То есть, нет расширения количества каналов внутри блока.  \n",
    "\n",
    "**Как это работает в контексте ResNet:**\n",
    "\n",
    "ResNet (Residual Network) использует \"бутылочные горлышки\" (bottleneck blocks) и базовые блоки (basic blocks) в качестве строительных блоков.  Разница между ними заключается в количестве слоев и в том, как изменяется количество каналов.\n",
    "\n",
    "* **Basic Block:**  Имеет два сверточных слоя 3x3. Количество каналов остается постоянным на протяжении всего блока и равно `out_channels`.  `expansion = 1` отражает это.\n",
    "\n",
    "* **Bottleneck Block:** Имеет три сверточных слоя: 1x1, 3x3 и 1x1.  Первый слой 1x1 уменьшает количество каналов, средний слой 3x3 обрабатывает информацию с уменьшенным количеством каналов, а последний слой 1x1 восстанавливает количество каналов до исходного значения, умноженного на `expansion`.  В типичной реализации Bottleneck блока `expansion = 4`.\n",
    "\n",
    "\n",
    "**Зачем нужен `expansion`:**\n",
    "\n",
    "`expansion` позволяет гибко контролировать количество каналов в разных блоках ResNet.  Это важно для балансирования сложности модели и ее способности извлекать признаки.  Bottleneck блоки с `expansion > 1` позволяют уменьшить количество параметров в промежуточных слоях, что делает модель более эффективной с точки зрения вычислений.  В `BasicBlock`, где `expansion = 1`,  просто сохраняется одинаковое количество каналов на входе и выходе блока, сохраняя простоту структуры.\n",
    "\n",
    "\n",
    "**В данном примере:**  `BasicBlock` с `expansion = 1`  - это самый простой тип блока в ResNet,  где количество каналов не меняется внутри блока.  Это означает, что `out_channels`  определяет количество каналов как на выходе блока, так и в промежуточных слоях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b40e832-3b73-4564-b232-1fd8112ca0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234bbb93-e23e-48fd-b4bd-d672c94258a1",
   "metadata": {},
   "source": [
    "### Bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea92018-7dee-4217-8ff1-8b77f5d33114",
   "metadata": {},
   "source": [
    "Этот код определяет класс `Bottleneck`, который, как и `BasicBlock`, является строительным блоком для ResNet, но имеет более сложную структуру, предназначенную для более глубоких сетей.  Ключевое отличие - использование \"бутылочного горлышка\" (bottleneck) в архитектуре блока и `expansion = 4`.\n",
    "\n",
    "**1. `expansion = 4`:**  Этот атрибут указывает, что количество выходных каналов блока в четыре раза больше значения `out_channels`, переданного в конструктор.  Расширение каналов происходит в последнем сверточном слое.\n",
    "\n",
    "**2. `__init__(self, in_channels, out_channels, stride=1, downsample=None)`:** Конструктор определяет слои блока:\n",
    "\n",
    "* **`self.conv1 = conv1x1(in_channels, out_channels)`:** Первый сверточный слой 1x1 **уменьшает** количество каналов с `in_channels` до `out_channels`. Это \"сжатие\" в бутылочном горлышке, которое уменьшает количество параметров и вычислений.\n",
    "* **`self.conv2 = conv3x3(out_channels, out_channels, stride)`:** Второй сверточный слой 3x3 обрабатывает информацию с уменьшенным количеством каналов (`out_channels`).  Здесь применяется `stride`, если нужно уменьшить пространственное разрешение карты признаков.\n",
    "* **`self.conv3 = conv1x1(out_channels, out_channels * self.expansion)`:** Третий сверточный слой 1x1 **расширяет** количество каналов до `out_channels * 4`. Это \"расширение\" в бутылочном горлышке, восстанавливающее размерность каналов, но с увеличенной в 4 раза шириной.\n",
    "* **`self.bn1`, `self.bn2`, `self.bn3`:** Batch Normalization слои после каждого сверточного слоя для нормализации активаций и ускорения обучения.\n",
    "* **`self.relu = nn.ReLU(inplace=True)`:** ReLU функция активации, применяемая после каждого слоя Batch Normalization, кроме финального.  `inplace=True` позволяет выполнять операцию без выделения дополнительной памяти.\n",
    "* **`self.downsample`:**  Аналогично `BasicBlock`, используется для согласования размерностей, если `stride > 1` или `in_channels != out_channels * expansion`.  Позволяет корректно выполнить сложение в residual connection.\n",
    "\n",
    "\n",
    "**3. `forward(self, x)`:** Метод прямого прохода:\n",
    "\n",
    "* **`identity = x`:** Сохранение входного тензора для residual connection.\n",
    "* Последовательность `conv -> bn -> relu` для первых двух сверточных слоев.\n",
    "* `conv3 -> bn3`:  Третий сверточный слой с последующей Batch Normalization, но **без ReLU**.\n",
    "* **`if self.downsample is not None: identity = self.downsample(x)`:** Применение `downsample` к входному тензору, если необходимо.\n",
    "* **`out += identity`:** Residual connection - суммирование выхода bottleneck слоя с преобразованным или исходным входным тензором.\n",
    "* **`out = self.relu(out)`:** Финальная ReLU активация после суммирования.  Обратите внимание, что ReLU применяется **после** сложения в residual connection.  \n",
    "\n",
    "\n",
    "**В итоге:** `Bottleneck` блок использует структуру \"бутылочного горлышка\" 1x1 -> 3x3 -> 1x1 для более эффективной обработки информации и уменьшения количества параметров по сравнению с последовательностью слоев 3x3.  `expansion = 4` увеличивает количество выходных каналов. Residual connection обеспечивает эффективное обучение глубоких сетей. `Bottleneck` блоки используются в более глубоких вариантах ResNet (например, ResNet50, ResNet101, ResNet152).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c57ce5c3-4f1a-4fcd-8ead-13131447b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv1x1(in_channels, out_channels)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = conv1x1(out_channels, out_channels*self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029d0db-af1c-4bb9-846a-7d65b7acb373",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af574c9-de23-4db4-8ed7-90111b555413",
   "metadata": {},
   "source": [
    "Этот код реализует класс `MyResNet`, который позволяет создавать различные варианты архитектуры ResNet (ResNet18, ResNet34, ResNet50, ResNet101, ResNet152) в зависимости от входного параметра `name`. Код хорошо структурирован и следует общим принципам построения ResNet.\n",
    "\n",
    "**Разберем подробнее:**\n",
    "\n",
    "**1. `cfgs`:** Словарь, содержащий конфигурации для разных вариантов ResNet.  Ключ - имя модели (например, \"resnet18\"), значение - кортеж из двух элементов:\n",
    "   *  Тип блока (`BasicBlock` или `Bottleneck`).\n",
    "   *  Список, определяющий количество блоков в каждом из четырех слоев ResNet.  Например, `[2, 2, 2, 2]` для ResNet18 означает 2 блока в каждом слое.\n",
    "\n",
    "**2. `__init__(self, name, num_classes=1000)`:** Конструктор класса.\n",
    "\n",
    "* **`name`:** Строка, определяющая архитектуру ResNet (например, \"resnet50\").\n",
    "* **`num_classes`:** Количество классов для классификации (по умолчанию 1000 для ImageNet).\n",
    "* **`block, layers = self.cfgs[name]`:** Извлекает тип блока и количество блоков для заданной архитектуры из словаря `cfgs`.\n",
    "* **`self.inplanes = 64`:** Инициализирует количество каналов на входе первого слоя.  Это значение будет обновляться в `make_layer`.\n",
    "* **`self.conv1`, `self.bn1`, `self.relu`, `self.maxpool`:**  Первый сверточный слой 7x7 со `stride=2` и `padding=3`, Batch Normalization, ReLU активация и Max Pooling слой 3x3 со `stride=2` и `padding=1`.  Это начальные слои, общие для всех вариантов ResNet.\n",
    "* **`self.layer1`, `self.layer2`, `self.layer3`, `self.layer4`:** Четыре основных слоя ResNet, каждый из которых состоит из нескольких блоков (`BasicBlock` или `Bottleneck`), определяемых `make_layer`.\n",
    "* **`self.avgpool`:**  Average Pooling слой 7x7. **Важно:** как и обсуждали ранее, лучше использовать `nn.AdaptiveAvgPool2d((1, 1))` для входных изображений разных размеров.\n",
    "* **`self.flatten`:** Преобразование многомерного тензора в одномерный вектор.\n",
    "* **`self.fc`:** Полносвязный слой для классификации с количеством выходных нейронов, равным `num_classes`.\n",
    "\n",
    "\n",
    "**3. `forward(self, x)`:**  Метод прямого прохода.  Последовательно применяет все слои к входному тензору `x` и возвращает результат `out` полносвязного слоя.\n",
    "\n",
    "**4. `make_layer(self, block, out_channels, blocks, stride=1)`:**  Функция, создающая слой ResNet, состоящий из нескольких блоков.\n",
    "\n",
    "* **`block`:** Тип блока (`BasicBlock` или `Bottleneck`).\n",
    "* **`out_channels`:**  Желаемое количество выходных каналов для блока.  Обратите внимание, что реальное количество выходных каналов блока будет `out_channels * block.expansion`.\n",
    "* **`blocks`:** Количество блоков в слое.\n",
    "* **`stride`:** Шаг свертки для первого блока в слое.  \n",
    "* **`downsample`:** Создает `downsample` слой (свертка 1x1 + Batch Normalization), если необходимо согласовать размерности между входом слоя и выходом первого блока.\n",
    "* Цикл создает нужное количество блоков и добавляет их в список `layers`.  **Важно:** `downsample` применяется только к первому блоку в слое.\n",
    "* Возвращает `nn.Sequential(*layers)` - контейнер, который последовательно применяет все блоки в слое.  \n",
    "\n",
    "\n",
    "**В целом:**  Код представляет собой хорошую реализацию ResNet, позволяющую создавать разные варианты архитектуры.  Однако, рекомендуется заменить `nn.AvgPool2d((7,7))` на `nn.AdaptiveAvgPool2d((1, 1))` для большей гибкости.  Также стоит обратить внимание на применение `downsample` только к первому блоку в слое и убедиться, что это соответствует выбранной архитектуре ResNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93d672fe-8f1d-421e-bc41-b40f1cb39323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    cfgs = {\n",
    "        \"resnet18\":(BasicBlock,[2, 2, 2, 2]),\n",
    "        \"resnet34\":(BasicBlock,[3, 4, 6, 3]),\n",
    "        \"resnet50\":(Bottleneck,[3, 4, 6, 3]),\n",
    "        \"resnet101\":(Bottleneck,[3, 4, 23, 3]),\n",
    "        \"resnet152\":(Bottleneck,[3, 8, 36, 3])\n",
    "    }\n",
    "\n",
    "    def __init__(self, name, num_classes=1000):\n",
    "        super().__init__()\n",
    "        block, layers = self.cfgs[name]\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, (7,7), stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d((3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d((7,7))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        out = self.fc(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, out_channels*block.expansion, stride),\n",
    "                nn.BatchNorm2d(out_channels*block.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.inplanes, out_channels, stride, downsample)\n",
    "        )\n",
    "\n",
    "        self.inplanes = out_channels * block.expansion\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.inplanes, out_channels)\n",
    "            )\n",
    "            \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53dd9d50-964a-4a28-b0fc-ac7132cfff90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=0)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим модель\n",
    "model = MyResNet('resnet18')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "437bc6e7-1798-4bcd-8239-745ab97ccd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# проверим работу созданной модели\n",
    "inp = torch.rand([1, 3, 224, 224], dtype=torch.float32)\n",
    "pred = model(inp)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa9101-91bb-4864-aede-cb61fc5c99f1",
   "metadata": {},
   "source": [
    "### Готовые архитектуры ResNet в Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40abe64-a8c5-4688-9353-4fe9fbd74a57",
   "metadata": {},
   "source": [
    "В данной части все по сути аналогично VGG (см. предыдущий ноутбук)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3215e40-0975-42df-91d9-10a48dc243d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим готовую модель из модуля\n",
    "model = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15577255-a7ec-441e-8f78-662e7f0f3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/talium/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "\n",
      "00%|██████████████████████████████████████| 97.8M/97.8M [00:01<00:00, 54.4MB/s]"
     ]
    }
   ],
   "source": [
    "# создадим модель с предобученными весами\n",
    "model = models.resnet50(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e2c2681-7994-4b34-bf27-919b65c2ef0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
